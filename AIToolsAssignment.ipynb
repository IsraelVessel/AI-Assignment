{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0137e24e",
   "metadata": {},
   "source": [
    "[Open in Colab](https://colab.research.google.com/github/IsraelVessel/AI-Assignment/blob/main/AIToolsAssignment.ipynb)  \n",
    "# AI Tools Assignment ‚Äî Mastering the AI Toolkit üõ†Ô∏èüß†\n",
    "\n",
    "This notebook contains the Theory, Practical implementations, Ethics & Optimization, and a Colab helper to run heavy tasks (MNIST) on GPU. Run cells in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colab helper: mount Drive, install deps, train MNIST, save artifacts\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_out = '/content/drive/MyDrive/AI_Assignment_Artifacts'\n",
    "    import os\n",
    "    os.makedirs(base_out, exist_ok=True)\n",
    "    print('Drive mounted. Artifacts will be saved to', base_out)\n",
    "except Exception as e:\n",
    "    base_out = '/content'\n",
    "    print('Drive not mounted, saving artifacts locally to /content', e)\n",
    "\n",
    "# Install packages (optional in Colab)\n",
    "!pip install -q tensorflow==2.12.0 scikit-learn spacy matplotlib pillow\n",
    "!python -m spacy download en_core_web_sm -q\n",
    "\n",
    "print('Helper ready. Use the MNIST cell below to train the model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07303fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 ‚Äî Theory answers (compact)\n",
    "\n",
    "# Q1: TensorFlow vs PyTorch\n",
    "# - TensorFlow: production tooling, TF Serving/TF Lite, Keras API for high-level models.\n",
    "# - PyTorch: pythonic, eager-first, popular in research.\n",
    "\n",
    "# Q2: Jupyter use cases\n",
    "# 1. EDA and visualization.\n",
    "# 2. Prototyping models and sharing reproducible experiments.\n",
    "\n",
    "# Q3: spaCy vs string ops\n",
    "# spaCy provides robust tokenization, POS tagging, dependency parsing, pretrained NER, and matchers ‚Äî far more reliable than ad-hoc string rules.\n",
    "\n",
    "print('Theory section: read markdown cells for full answers.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8621c7db",
   "metadata": {},
   "source": [
    "## Part 1 ‚Äî Theory (short answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec60fe7",
   "metadata": {},
   "source": [
    "## Part 2 ‚Äî Practical: Iris (scikit-learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc792c6",
   "metadata": {},
   "source": [
    "# Iris Decision Tree example\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "data = load_iris(as_frame=False)\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5740959",
   "metadata": {},
   "source": [
    "## Part 2 ‚Äî Practical: MNIST CNN (run in Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a8827",
   "metadata": {},
   "source": [
    "# MNIST CNN (Colab recommended)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype('float32')/255.0\n",
    "x_test = x_test.astype('float32')/255.0\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=8, batch_size=128, validation_split=0.1)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy:', test_acc)\n",
    "\n",
    "# Save sample predictions and plots to base_out if available\n",
    "try:\n",
    "    out = base_out\n",
    "except NameError:\n",
    "    out = '/content'\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.savefig(str(out) + '/mnist_training.png')\n",
    "plt.close()\n",
    "\n",
    "import random\n",
    "idx = random.sample(range(len(x_test)), 5)\n",
    "preds = model.predict(x_test[idx])\n",
    "fig, axs = plt.subplots(1,5, figsize=(12,3))\n",
    "for i, j in enumerate(idx):\n",
    "    axs[i].imshow(x_test[j].squeeze(), cmap='gray')\n",
    "    axs[i].set_title(f'Pred: {np.argmax(preds[i])}\\nTrue: {y_test[j]}')\n",
    "    axs[i].axis('off')\n",
    "fig.savefig(str(out) + '/mnist_samples.png')\n",
    "fig.clf()\n",
    "model.save(str(out) + '/mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc0c42",
   "metadata": {},
   "source": [
    "## Part 2 ‚Äî Practical: spaCy NER & simple sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db82ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy NER demo\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "reviews = [\n",
    "    'I love the Acme SmartWatch, the battery lasts all week and the strap is comfortable.',\n",
    "    'The Zeta Vacuum is noisy and stopped working after two weeks. Terrible experience.',\n",
    "    'Great headphones by SoundMax ‚Äî amazing bass and clear mids.'\n",
    "]\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "patterns = [nlp.make_doc('Acme SmartWatch'), nlp.make_doc('Zeta Vacuum'), nlp.make_doc('SoundMax')]\n",
    "matcher.add('PRODUCT', patterns)\n",
    "lines = []\n",
    "for r in reviews:\n",
    "    doc = nlp(r)\n",
    "    ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    matches = matcher(doc)\n",
    "    found = [doc[start:end].text for _, start, end in matches]\n",
    "    lines.append('Review: ' + r)\n",
    "    lines.append('Entities: ' + str(ents))\n",
    "    lines.append('Matched: ' + str(found))\n",
    "    lines.append('')\n",
    "\n",
    "# render text to PNG for report\n",
    "txt = '\\n'.join(lines)\n",
    "W, H = (1200, 400)\n",
    "img = Image.new('RGB', (W, H), color='white')\n",
    "draw = ImageDraw.Draw(img)\n",
    "try:\n",
    "    font = ImageFont.truetype('DejaVuSansMono.ttf', 14)\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "draw.multiline_text((10,10), txt, fill='black', font=font)\n",
    "out_path = base_out if 'base_out' in globals() else '/content'\n",
    "img.save(str(out_path) + '/spacy_ner.png')\n",
    "print('Saved spaCy NER output to', str(out_path) + '/spacy_ner.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd04b39",
   "metadata": {},
   "source": [
    "## Part 3 ‚Äî Ethics & Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Biases: MNIST and Reviews\n",
    "- MNIST: handwriting diversity and scanner/camera differences can bias models.\n",
    "- Reviews: rule-based sentiment fails on sarcasm and cultural language.\n",
    "\n",
    "### Mitigations\n",
    "- Data augmentation, auditing datasets for diversity, and using human-in-the-loop evaluation for sensitive predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8696d09",
   "metadata": {},
   "source": [
    "## How to run\n",
    "- For best results, open this notebook in Colab using the link at the top, enable GPU, then run the Colab helper cell (Cell 2) and the MNIST cell (Cell 6).\n",
    "- After running, download artifacts from Drive (/MyDrive/AI_Assignment_Artifacts/) and share them here for final PDF assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9f94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final notes: This notebook is intentionally concise. For detailed code and alternative scripts, see the repository files: `mnist_cnn.py`, `iris_classification.py`, `spacy_ner_sentiment.py`, and `md_to_pdf.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd9ddc",
   "metadata": {},
   "source": [
    "## Part 3: Ethics & Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e1337",
   "metadata": {},
   "source": [
    "Acknowledgements: Use Colab for GPU-heavy tasks. If you prefer local runs, ensure TensorFlow is installed and your Python version matches TF's supported list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae7f45",
   "metadata": {},
   "source": [
    "Contact: If you want, I can now run quick smoke tests, regenerate the PDF with embedded images (if you upload them or after the Colab run), and push the final artifacts to the repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5442b204",
   "metadata": {},
   "source": [
    "Last updated: AI assistant ‚Äî GitHub Copilot. Small edits are safe; let me know if you want full expanded answers inserted as code cells instead."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
